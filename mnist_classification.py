# -*- coding: utf-8 -*-
"""mnist_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CRrhYFRhkBovYAYk58ApQoIVAsWOMKoy

MNIST Handwritten Digit Classification Project

This script provides a complete workflow for classifying the MNIST dataset.
It covers the following steps:
1.  Loading and exploring the MNIST dataset.
2.  Preprocessing the data (scaling and splitting).
3.  Training three different machine learning models:
    - Logistic Regression (as a baseline)
    - K-Nearest Neighbors (KNN)
    - Random Forest Classifier
4.  Evaluating each model using accuracy, a classification report, and a confusion matrix.
5.  Performing a simple error analysis on the best-performing model.
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler

# --- Phase 1: Data Handling and Exploration ---

def load_and_explore_data():
    print("Step 1: Loading MNIST dataset...")
    mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='liac-arff')
    print("Dataset loaded successfully!")

    X, y = mnist["data"], mnist["target"]
    y = y.astype(np.uint8)

    print(f"Image data shape (X): {X.shape}")
    print(f"Labels shape (y): {y.shape}")
    # --- Initial Exploration (EDA) ---
    print("\nVisualizing some random digits from the dataset...")
    plt.figure(figsize=(10, 4))
    for i in range(10):
        plt.subplot(2, 5, i + 1)
        # Reshape the 784-pixel vector back to a 28x28 image
        image = X[i].reshape(28, 28)
        plt.imshow(image, cmap="binary")
        plt.title(f"Label: {y[i]}")
        plt.axis('off')
    plt.suptitle("Sample MNIST Digits", fontsize=16)

    # Save the figure to a file
    plt.savefig('mnist_samples.png')
    print("Saved sample digits plot to 'mnist_samples.png'")

    plt.show()

    return X, y

# --- Phase 2: Preprocessing and Preparation ---

def preprocess_data(X, y):
    print("\nStep 2: Preprocessing data...")
    X_train, X_test = X[:60000], X[60000:]
    y_train, y_test = y[:60000], y[60000:]

    print(f"Training set size: {X_train.shape[0]} samples")
    print(f"Test set size: {X_test.shape[0]} samples")

    # --- Feature Scaling ---
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))
    X_test_scaled = scaler.transform(X_test.astype(np.float64))
    print("Data has been scaled using StandardScaler.")

    return X_train_scaled, X_test_scaled, y_train, y_test

# --- Phase 3: Model Building and Evaluation ---

def train_and_evaluate_models(X_train, X_test, y_train, y_test):
    print("\nStep 3: Training and Evaluating Models...")

    # Define the models to be trained
    models = {
        "Logistic Regression": LogisticRegression(max_iter=1000, solver='saga', tol=0.1, n_jobs=-1),
        "K-Nearest Neighbors": KNeighborsClassifier(n_jobs=-1),
        "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
    }

    results = {}

    for name, model in models.items():
        print(f"\n--- Training {name} ---")
        model.fit(X_train, y_train)

        print(f"--- Evaluating {name} ---")
        y_pred = model.predict(X_test)

        # --- Evaluation ---
        accuracy = accuracy_score(y_test, y_pred)
        report = classification_report(y_test, y_pred)
        conf_matrix = confusion_matrix(y_test, y_pred)

        results[name] = {
            "model": model,
            "accuracy": accuracy,
            "report": report,
            "confusion_matrix": conf_matrix
        }

        # Print metrics
        print(f"Accuracy: {accuracy:.4f}")
        print("Classification Report:")
        print(report)

        # Visualize confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))
        plt.xlabel("Predicted Label")
        plt.ylabel("True Label")
        plt.title(f"Confusion Matrix for {name}")

        # Save the figure to a file
        plt.savefig(f'confusion_matrix_{name.replace(" ", "_")}.png')
        print(f"Saved confusion matrix to 'confusion_matrix_{name.replace(" ", "_")}.png'")

        plt.show()

    return results

# --- Phase 4: Error Analysis ---

def analyze_errors(results, X_test_unscaled, y_test, mnist):
    print("\nStep 4: Analyzing Misclassifications from the Best Model...")

    # Find the best model based on accuracy
    best_model_name = max(results, key=lambda name: results[name]['accuracy'])
    best_model = results[best_model_name]['model']
    print(f"The best model is: {best_model_name} with an accuracy of {results[best_model_name]['accuracy']:.4f}")

    scaler = StandardScaler()
    # _, y_full = load_and_explore_data() # Removed redundant data loading
    X_full, _ = mnist["data"], mnist["target"] # Re-use from the passed mnist object
    X_train_full = X_full[:60000]
    scaler.fit(X_train_full)
    X_test_scaled_again = scaler.transform(X_test_unscaled)

    y_pred = best_model.predict(X_test_scaled_again)

    # Find the indices of misclassified images
    misclassified_indices = np.where(y_pred != y_test)[0]

    # Display a few of them
    plt.figure(figsize=(12, 5))
    for i, img_index in enumerate(misclassified_indices[:10]):
        plt.subplot(2, 5, i + 1)
        image = X_test_unscaled[img_index].reshape(28, 28)
        plt.imshow(image, cmap="binary")
        plt.title(f"True: {y_test[img_index]}\nPred: {y_pred[img_index]}")
        plt.axis('off')
    plt.suptitle("Examples of Misclassified Digits", fontsize=16)

    # Save the figure to a file
    plt.savefig('misclassified_digits.png')
    print("Saved misclassified digits plot to 'misclassified_digits.png'")

    plt.show()

# --- Main Execution Block ---

if __name__ == "__main__":
    mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='liac-arff')
    X, y = mnist["data"], mnist["target"]
    y = y.astype(np.uint8)

    # Preprocess the data for the models
    X_train_scaled, X_test_scaled, y_train, y_test = preprocess_data(X, y)
    model_results = train_and_evaluate_models(X_train_scaled, X_test_scaled, y_train, y_test)

    # Analyze the errors of the best model
    X_test_unscaled = X[60000:]
    analyze_errors(model_results, X_test_unscaled, y_test, mnist) # Pass mnist object

    print("\nProject workflow complete!")

